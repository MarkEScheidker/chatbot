{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223dcf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\marks\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\marks\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\marks\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marks\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [44 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 35, in __init__\n",
      "      parsed = _parse_requirement(requirement_string)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 64, in parse_requirement\n",
      "      return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 82, in _parse_requirement\n",
      "      url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 126, in _parse_requirement_details\n",
      "      marker = _parse_requirement_marker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 147, in _parse_requirement_marker\n",
      "      tokenizer.raise_syntax_error(\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_tokenizer.py\", line 165, in raise_syntax_error\n",
      "      raise ParserSyntaxError(\n",
      "  setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\marks\\AppData\\Local\\Temp\\pip-install-sf4ucylv\\tensorflow-gpu_60176199177f45868310352cb35ba943\\setup.py\", line 40, in <module>\n",
      "      setuptools.setup()\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py\", line 106, in setup\n",
      "      _install_setup_requires(attrs)\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py\", line 77, in _install_setup_requires\n",
      "      dist.parse_config_files(ignore_option_errors=True)\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 900, in parse_config_files\n",
      "      self._finalize_requires()\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 597, in _finalize_requires\n",
      "      self._move_install_requirements_markers()\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 637, in _move_install_requirements_markers\n",
      "      inst_reqs = list(_reqs.parse(spec_inst_reqs))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 37, in __init__\n",
      "      raise InvalidRequirement(str(e)) from e\n",
      "  setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install tensorflow-gpu\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, set_seed\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2f48c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(123)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "903e3d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21d3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "target_sequences = []\n",
    "\n",
    "with open(\"dataset.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        question, answer = line.strip().split('\\t')\n",
    "        combined_text = question + tokenizer.eos_token + answer\n",
    "        encoded = tokenizer.encode_plus(combined_text, max_length=64, truncation=True, padding=\"max_length\", return_tensors=\"tf\")\n",
    "        input_sequences.append(encoded['input_ids'][0])\n",
    "        target_sequences.append(tf.concat([encoded['input_ids'][0][1:], [tokenizer.pad_token_id]], axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707b6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
    "dataset = dataset.shuffle(1024).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fefc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cde2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marks\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      " 48/117 [===========>..................] - ETA: 3:07:36 - loss: 10.8244"
     ]
    }
   ],
   "source": [
    "model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427583c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('fine_tuned_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained('fine_tuned_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c214fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def generate_text(prompt, max_length=50, temperature=0.7, top_k=50):\n",
    "    generated_text = prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        outputs = model(input_ids)\n",
    "        predictions = outputs.logits[:, -1, :]\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "\n",
    "        top_k_values, top_k_indices = tf.nn.top_k(predictions, k=top_k)\n",
    "        values = tf.nn.softmax(top_k_values, axis=-1)\n",
    "        sampled_token_index = tf.random.categorical(tf.math.log(values), num_samples=1)\n",
    "        sampled_token_id = tf.gather(top_k_indices, sampled_token_index, batch_dims=1).numpy().squeeze()\n",
    "\n",
    "        if sampled_token_id == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "        generated_text += tokenizer.decode([sampled_token_id])\n",
    "        input_ids = tf.concat([input_ids, [[sampled_token_id]]], axis=-1)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \" \"\n",
    "generated_text = generate_text(prompt, max_length=100)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4651801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24135cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1b5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
