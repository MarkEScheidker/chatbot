{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223dcf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[44 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_vendor/packaging/requirements.py\", line 35, in __init__\n",
      "  \u001b[31m   \u001b[0m     parsed = _parse_requirement(requirement_string)\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
      "  \u001b[31m   \u001b[0m     return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
      "  \u001b[31m   \u001b[0m     url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_vendor/packaging/_parser.py\", line 126, in _parse_requirement_details\n",
      "  \u001b[31m   \u001b[0m     marker = _parse_requirement_marker(\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_vendor/packaging/_parser.py\", line 147, in _parse_requirement_marker\n",
      "  \u001b[31m   \u001b[0m     tokenizer.raise_syntax_error(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_vendor/packaging/_tokenizer.py\", line 165, in raise_syntax_error\n",
      "  \u001b[31m   \u001b[0m     raise ParserSyntaxError(\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-ppm9ofdj/tensorflow-gpu_1a5223c192d440a89c9493fe04c90cf7/setup.py\", line 40, in <module>\n",
      "  \u001b[31m   \u001b[0m     setuptools.setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/__init__.py\", line 102, in setup\n",
      "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/__init__.py\", line 73, in _install_setup_requires\n",
      "  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/dist.py\", line 629, in parse_config_files\n",
      "  \u001b[31m   \u001b[0m     self._finalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/dist.py\", line 364, in _finalize_requires\n",
      "  \u001b[31m   \u001b[0m     self._normalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/dist.py\", line 379, in _normalize_requires\n",
      "  \u001b[31m   \u001b[0m     self.install_requires = list(map(str, _reqs.parse(install_requires)))\n",
      "  \u001b[31m   \u001b[0m                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_vendor/packaging/requirements.py\", line 37, in __init__\n",
      "  \u001b[31m   \u001b[0m     raise InvalidRequirement(str(e)) from e\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hRequirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.0.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.42.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 16:31:53.316272: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install tensorflow-gpu\n",
    "!pip install tf-keras\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, set_seed\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2f48c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(123)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "903e3d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 16:31:55.332337: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 16:31:55.335874: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 16:31:55.335901: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 16:31:55.337357: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 16:31:55.337384: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 16:31:55.337400: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 16:31:55.418720: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 16:31:55.418763: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 16:31:55.418771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-30 16:31:55.418782: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-04-30 16:31:55.418994: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 16:31:55.419018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21d3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "target_sequences = []\n",
    "\n",
    "with open(\"dataset.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        question, answer = line.strip().split('\\t')\n",
    "        combined_text = question + tokenizer.eos_token + answer\n",
    "        encoded = tokenizer.encode_plus(combined_text, max_length=64, truncation=True, padding=\"max_length\", return_tensors=\"tf\")\n",
    "        input_sequences.append(encoded['input_ids'][0])\n",
    "        target_sequences.append(tf.concat([encoded['input_ids'][0][1:], [tokenizer.pad_token_id]], axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707b6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
    "dataset = dataset.shuffle(1024).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fefc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.optimizers.Adam.learning_rate = 0.001\n",
    "tf.keras.optimizers.Adam.beta_1 = 0.9\n",
    "tf.keras.optimizers.Adam.beta_2 = 0.999\n",
    "tf.keras.optimizers.Adam.epsilon = 1e-07\n",
    "tf.keras.optimizers.Adam.amsgrad = False\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287a5664-25a3-4a9f-a697-b70ca6d077d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0cde2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7fe6c70f6c00> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x7fe6c70f6c00> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714494747.470839    7373 service.cc:145] XLA service 0x7fe5c5648430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714494747.470882    7373 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-04-30 16:32:27.475791: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-30 16:32:27.489080: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n",
      "I0000 00:00:1714494747.531707    7373 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 41s 104ms/step - loss: 1.0250\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 13s 109ms/step - loss: 0.5924\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 0.4388\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 0.3519\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 0.2918\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 12s 104ms/step - loss: 0.2497\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 12s 104ms/step - loss: 0.2193\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 12s 104ms/step - loss: 0.1948\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 12s 104ms/step - loss: 0.1721\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 13s 108ms/step - loss: 0.1568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7fe6740ddc50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427583c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('fine_tuned_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ade5216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at fine_tuned_gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, set_seed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "model = TFGPT2LMHeadModel.from_pretrained('fine_tuned_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c214fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def generate_text(prompt, max_length=50, temperature=0.7, top_k=50):\n",
    "    seed = np.random.randint(0, 10000)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    prompt = prompt + tokenizer.pad_token\n",
    "    input_len = len(prompt)\n",
    "    generated_text = prompt \n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        outputs = model(input_ids)\n",
    "        predictions = outputs.logits[:, -1, :]\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "\n",
    "        top_k_values, top_k_indices = tf.nn.top_k(predictions, k=top_k)\n",
    "        values = tf.nn.softmax(top_k_values, axis=-1)\n",
    "        sampled_token_index = tf.random.categorical(tf.math.log(values), num_samples=1)\n",
    "        sampled_token_id = tf.gather(top_k_indices, sampled_token_index, batch_dims=1).numpy().squeeze()\n",
    "\n",
    "        if sampled_token_id == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "        generated_text += tokenizer.decode([sampled_token_id])\n",
    "        input_ids = tf.concat([input_ids, [[sampled_token_id]]], axis=-1)\n",
    "        \n",
    "    return generated_text [input_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9538263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: i used all my savings on this one.\n",
      "Generated text: i don't know. look in the fridge.\n",
      "Generated text: i don't know.\n",
      "Generated text: i don't know. maybe prices are cheaper than police?\n",
      "Generated text: i know that.\n",
      "Generated text: i bought it from the macy's at the santa anita mall.\n",
      "Generated text: i know, i don't want to eat there.\n",
      "Generated text: i don't know.\n",
      "Generated text: i filled up on the bread.\n",
      "Generated text: i know, i don't like to eat leftovers.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"where can I find the best food around here?\"\n",
    "\n",
    "for i in range(10):\n",
    "    generated_text = generate_text(prompt, max_length=100)\n",
    "    print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72efe3-c00f-4685-aef8-4dcc1a1c98d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e60703-4f0d-44e4-bf2e-68b4750e6491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
